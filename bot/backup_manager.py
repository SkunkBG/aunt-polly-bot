import asyncio
import json
import logging
import os
import zipfile
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import List, Optional, Tuple

from aiogram import Bot
from aiogram.types import FSInputFile
from zoneinfo import ZoneInfo

from bot import config

logger = logging.getLogger(__name__)


BACKUPS_DIR = Path("bot/backups")

# –•—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –±—ç–∫–∞–ø–æ–≤ (—Å—Ç–∞—Ä—ã–µ —É–¥–∞–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
MAX_BACKUPS_KEEP = 3


@dataclass
class BackupInfo:
    path: Path
    created_at: datetime


def _parse_backup_time(value: str) -> Tuple[int, int]:
    """–ü–∞—Ä—Å–∏—Ç BACKUP_TIME –≤–∏–¥–∞ HH:MM."""
    try:
        hh, mm = value.strip().split(":")
        h = int(hh)
        m = int(mm)
        if not (0 <= h <= 23 and 0 <= m <= 59):
            raise ValueError
        return h, m
    except Exception:
        logger.warning("Invalid BACKUP_TIME='%s', fallback to 10:00", value)
        return 10, 0


def list_backups(limit: int = 10) -> List[BackupInfo]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –±—ç–∫–∞–ø–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–≤–µ—Ä—Ö—É)."""
    BACKUPS_DIR.mkdir(parents=True, exist_ok=True)
    items: List[BackupInfo] = []
    for p in BACKUPS_DIR.glob("aunt_polly_backup_*.zip"):
        try:
            ts = p.stem.replace("aunt_polly_backup_", "")
            created = datetime.strptime(ts, "%Y%m%d_%H%M%S").replace(tzinfo=timezone.utc)
        except Exception:
            created = datetime.fromtimestamp(p.stat().st_mtime, tz=timezone.utc)
        items.append(BackupInfo(path=p, created_at=created))
    items.sort(key=lambda x: x.created_at, reverse=True)
    return items[:limit]


def create_backup_file() -> Path:
    """–°–æ–∑–¥–∞—ë—Ç zip-–±—ç–∫–∞–ø –Ω–∞—Å—Ç—Ä–æ–µ–∫/FAQ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å."""
    BACKUPS_DIR.mkdir(parents=True, exist_ok=True)

    now_utc = datetime.now(timezone.utc)
    filename = f"aunt_polly_backup_{now_utc.strftime('%Y%m%d_%H%M%S')}.zip"
    out_path = BACKUPS_DIR / filename

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –µ—Å–ª–∏ –∞–¥–º–∏–Ω –º–µ–Ω—è–ª –∫–∞—Ä—Ç–∏–Ω–∫—É –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è ‚Äî –∫–ª–∞–¥—ë–º –µ—ë —Ç–æ–∂–µ –≤ –±—ç–∫–∞–ø
    settings = config.load_json(config.SETTINGS_FILE, default_data={})
    welcome_image_path = (settings.get("welcome_image_path") or "").strip()
    extra_files: List[str] = []
    if welcome_image_path:
        p_img = Path(welcome_image_path)
        if p_img.exists() and p_img.is_file():
            extra_files.append(welcome_image_path)

    manifest = {
        "app": "aunt-polly-bot",
        "format": 1,
        "created_at_utc": now_utc.isoformat(),
        "includes": [config.SETTINGS_FILE, config.FAQ_FILE] + extra_files,
    }

    with zipfile.ZipFile(out_path, "w", compression=zipfile.ZIP_DEFLATED) as z:
        # –ú–∞–Ω–∏—Ñ–µ—Å—Ç
        z.writestr("manifest.json", json.dumps(manifest, ensure_ascii=False, indent=2))

        # –§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö
        for rel in (config.SETTINGS_FILE, config.FAQ_FILE):
            p = Path(rel)
            if p.exists():
                z.write(p, arcname=str(p))
            else:
                # –°–æ—Ö—Ä–∞–Ω–∏–º –ø—É—Å—Ç—ã—à–∫—É, —á—Ç–æ–±—ã –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±—ã–ª–æ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–º
                z.writestr(str(p), "{}" if rel.endswith("settings.json") else "[]")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è)
        for rel in extra_files:
            p = Path(rel)
            if p.exists() and p.is_file():
                z.write(p, arcname=str(p))

    # –ê–≤—Ç–æ-–æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
    _cleanup_old_backups(MAX_BACKUPS_KEEP)

    logger.info("Backup created: %s", out_path)
    return out_path


def _cleanup_old_backups(max_keep: int) -> None:
    """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_keep."""
    try:
        backups = list_backups(limit=1000)
        if len(backups) <= max_keep:
            return
        to_delete = backups[max_keep:]
        for b in to_delete:
            try:
                b.path.unlink(missing_ok=True)
                logger.info("Deleted old backup: %s", b.path)
            except Exception:
                logger.warning("Could not delete old backup: %s", b.path, exc_info=True)
    except Exception:
        logger.warning("Backup cleanup failed", exc_info=True)


def restore_backup_file(zip_path: Path) -> str:
    """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏/FAQ –∏–∑ zip. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç."""
    if not zip_path.exists():
        raise FileNotFoundError(str(zip_path))

    restored = []
    with zipfile.ZipFile(zip_path, "r") as z:
        names = set(z.namelist())
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω, –Ω–æ –∂–µ–ª–∞—Ç–µ–ª–µ–Ω)
        manifest_includes: List[str] = []
        if "manifest.json" in names:
            try:
                manifest = json.loads(z.read("manifest.json").decode("utf-8"))
                manifest_includes = list(manifest.get("includes", []) or [])
                logger.info("Restoring backup manifest: %s", manifest)
            except Exception:
                logger.warning("Could not parse manifest.json in backup")

        # –ë–∞–∑–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        base_targets = [config.SETTINGS_FILE, config.FAQ_FILE]
        for arc in base_targets:
            if arc not in names:
                continue
            target = Path(arc)
            target.parent.mkdir(parents=True, exist_ok=True)
            target.write_bytes(z.read(arc))
            restored.append(arc)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞—Ä—Ç–∏–Ω–∫–∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è)
        for arc in manifest_includes:
            if arc in restored:
                continue
            if arc not in names:
                continue
            target = Path(arc)
            target.parent.mkdir(parents=True, exist_ok=True)
            target.write_bytes(z.read(arc))
            restored.append(arc)

    if not restored:
        return "–ù–µ—á–µ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å: –≤ –±—ç–∫–∞–ø–µ –Ω–µ—Ç settings/faq"
    return "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: " + ", ".join(restored)


async def send_backup_to_admin(bot: Bot, backup_path: Path, caption: str) -> None:
    await bot.send_document(
        chat_id=config.ADMIN_ID,
        document=FSInputFile(str(backup_path)),
        caption=caption,
    )


async def run_daily_backup_loop(bot: Bot) -> None:
    """–§–æ–Ω–æ–≤—ã–π —Ü–∏–∫–ª –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞–¥–º–∏–Ω—É."""
    tz = ZoneInfo(config.TIMEZONE) if config.TIMEZONE else timezone.utc
    logger.info("Daily backup scheduler enabled (%s)", tz)

    while True:
        # –ë–µ—Ä—ë–º –≤—Ä–µ–º—è –∏–∑ settings.json (–º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –∏–∑ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏ –±–µ–∑ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞)
        settings = config.load_json(config.SETTINGS_FILE, default_data={})
        bt = (settings.get("backup_time") or getattr(config, "BACKUP_TIME", "10:00")).strip()
        hour, minute = _parse_backup_time(bt)

        now = datetime.now(tz)
        next_run = now.replace(hour=hour, minute=minute, second=0, microsecond=0)
        if next_run <= now:
            next_run = next_run + timedelta(days=1)

        sleep_s = (next_run - now).total_seconds()
        logger.info("Next daily backup at %s (in %.0f sec)", next_run.isoformat(), sleep_s)
        await asyncio.sleep(max(1, sleep_s))

        try:
            p = create_backup_file()
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–¥–º–∏–Ω—É
            local_time = datetime.now(tz).strftime("%d.%m.%Y %H:%M")
            await send_backup_to_admin(
                bot,
                p,
                caption=f"üóÑÔ∏è –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –±—ç–∫–∞–ø –Ω–∞—Å—Ç—Ä–æ–µ–∫ ‚Ä¢ {local_time}\n\n–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç FAQ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏.",
            )
        except Exception as e:
            logger.error("Daily backup failed: %s", e, exc_info=True)
